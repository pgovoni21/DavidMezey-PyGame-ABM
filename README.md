# Visuospatial navigation without distance, prediction, or maps

<img src="./site_media/flow.png" width="800"/>

**Author of Model:** Patrick Govoni <br>
**Supervisors:** Prof. Pawel Romanczuk <br>
**Affiliation:** Institute for Theoretical Biology, Department of Biology, Humboldt Universität zu Berlin <br>
**Group:** [Collective Information Processing Lab](http://lab.romanczuk.de/) <br>
**Timespan:** 2023-Present

**Abstract:** <br>
Navigation is controlled by at least two partially dissociable, concurrently developed systems in the brain. 
The cognitive map informs an organism of its location, bearing, and distances between environmental features, enabling shortcuts. 
Response-based navigation, on the other hand, the process of composing percept-action pairs into routes, 
is regarded as inaccurate and inflexible, ultimately subserving map-based representation. 
As such, navigation models tend to assume the primacy of maps, 
top-down constructed via predictive control and distance perception, while neglecting response-based strategies. 
Here we show the sufficiency of a minimal feedforward framework in a classic visual navigation task. 
Our agents, directly translating visual perception to movement, navigate to a hidden goal in an open field, 
an environment often assumed to require map-based representation. 
While visual distance enables direct trajectories to the goal, 
two distinct algorithms develop to robustly navigate using visual angles alone. 
Each of the three confers unique contextual tradeoffs as well as aligns with behavior observed with rodents, 
insects, fish, and sperm cells, suggesting the widespread significance of response-based strategies. 
We advocate further study of navigation from the bottom-up without assuming online access to computationally expensive top-down representations, 
which may better explain behavior under energetic or attentional constraints.

<p float="left">
  <img src="./site_media/sim_IS_respawn.gif" width="250" />
  <img src="./site_media/sim_BD_respawn.gif" width="250" />
  <img src="./site_media/sim_DP_respawn.gif" width="250" />
</p>
<p float="left">
  <img src="./site_media/trajs_IS.png" width="250" />
  <img src="./site_media/trajs_BD.png" width="250" />
  <img src="./site_media/trajs_DP.png" width="250" />
</p>

<img src="./site_media/MWM.png" width="800"/>
<img src="./site_media/sperm.png" width="800"/>
<img src="./site_media/binary_choice.png" width="800"/>
<img src="./site_media/convergence.png" width="800"/>

**Manuscript:** <br>
[Preprint](https://arxiv.org/abs/2407.13535v2) <br>

**Citation:** <br>
Govoni, P., Romanczuk, P. Visuospatial navigation without distance, prediction, or maps. (2024). 

**License:** <br>
Copyright © 2023 [Patrick Govoni](https://github.com/pgovoni21). <br>
This project is [MIT](https://github.com/pgovoni21/vis-nav-abm?tab=MIT-1-ov-file) licensed.
